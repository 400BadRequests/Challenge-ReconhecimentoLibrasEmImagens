# -*- coding: utf-8 -*-
"""Challenge-Libras em Imagens.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XzeDkYNzc5W3scYpvbNFoefCQskQmBPj

#Mão - Traduzindo Libras em imagens

> Para a identificação mais dinâmica de várias posições, foram desenvolvidos 4 módulos para extrair algumas caracteríscas e comparar o deslocamento das articulações (pontos chave)

> Extraimos a ALTURA, POSIÇÃO e PROXIMIDADE entre os pontos chave detectados
>> Módulo extrator_ALTURA: verifica se um ponto está 'acima' ou 'abaixo' de outro ponto específico. Por exemplo, se a ponta do dedo está 'acima' do punho

>> Módulo extrator_POSICAO: funções para verificar se os dedos estão 'dobrados' ou 'esticados', na posição horizontal ou na vertical. Também recebe o resultado do módulo extrator_ALTURA para saber em que posição a mão está (voltada 'acima' ou 'abaixo')

>> Módulo extrator_PROXIMIDADE: funções que comparam a proximidade entre os pontos chaves detectados. Por exemplo, se o resultado do módulo extrator_POSICAO for igual a 'dobrado' para o dedo indicador e dedo médio e ambos estiverem na mesma altura, então significa que os dedos estão próximos

>> Módulo alfabeto: após extrair todas estas características, foi criado o alfabeto de características, onde um VETOR DE VETORES recebe o resultado de todos os módulos extratores. Assim usamos este módulo para comparar com uma nova análise (nova imagem) de entrada
# Não foram usadas as letras: H, J, K, X, ,Y , Z devido ao movimento adicional para a execução correta das letras.

# Estas letras podem ser analisadas em uma função diferente, semelhante a função de análise de posicionamento do corpo, onde comparamos a transição entre pontos

# Letra T: para o dedo polegar, devido a estar sobreposto pelo dedo indicador, o algoritmo não reconhece os pontos da ponta do dedo

# Letra N e U se confundem

## **Etapa 1 - Importando as bibliotecas**
"""

import sys #para ter acesso aos recursos do sistema
import cv2 #lib do opencv
import numpy as np #lib 
import matplotlib.pyplot as plt

print("Versão do cv2: ", cv2.__version__)

"""## **Etapa 2 - Conectando com o Drive**



"""

"""## Etapa 3 - Importando os módulos

"""

#importando os modulos para a tradução
from modulos import extrator_POSICAO as posicao
from modulos import extrator_ALTURA as altura
from modulos import extrator_PROXIMIDADE as proximidade
from modulos import alfabeto

"""## **Etapa 4 - Carregando o modelo e estruturas da rede neural pré-treinada**"""

arquivo_proto = "pose/hand/pose_deploy.prototxt" #Estrutura da rede neural
arquivo_pesos = "pose/hand/pose_iter_102000.caffemodel" #Pesos previamente treinados
numero_pontos = 22 #Numeros de pontos desse modelo
#ligação dos pontos da mão
pares_poses = [[0, 1], [1, 2], [2, 3], [3, 4], [0, 5], [5, 6], [6, 7], [7, 8], 
              [0, 9], [9, 10], [10, 11], [11, 12], [0, 13], [13, 14], [14, 15],
              [15, 16], [0, 17], [17, 18], [18, 19], [19, 20]]

#Array de letras que vai ser associado ao arquivo alfabeto.py
letras = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'I', 'L', 'M', 'N', 'O', 'P', 'Q',
          'R', 'S', 'T', 'U', 'V', 'W']

"""## **Etapa 5 - Ler o modelo carregado na Etapa 3**


"""

modelo = cv2.dnn.readNetFromCaffe(arquivo_proto, arquivo_pesos) #Fazendo a leitura e carregando o modelo já treinado

"""## **Etapa 6 - Carregando uma imagem do Drive.**"""

imagem = cv2.imread("imagens/hand/Libras/B.JPG") #Carregando a imagem

cv2.imshow("Carregando a imagem", imagem) #Mostrando a imagem

imagem_copia = np.copy(imagem) #Fazendo a copia da imagem

#Setando a altura e a largura da imagem
imagem_largura = imagem.shape[1] 
imagem_altura = imagem.shape[0]
proporcao = imagem_largura / imagem_altura

print(imagem_largura, imagem_altura, proporcao) #mostrando as variaveis setadas

cor_pontoA, cor_pontoB, cor_linha = (14, 201, 255), (255, 0, 128), (192, 192, 192) #Setando as cores dos pontos
cor_txtponto = (10, 216, 245) #Setando a cor do ponto

tamanho_fonte, tamanho_linha, tamanho_circulo, espessura = 5, 1, 4, 2 #Setando o tamanho da fonte dos pontos

fonte = cv2.FONT_HERSHEY_SIMPLEX #setando a fonte do ponto

"""## **Etapa 7 - Definir as dimensões da imagem de entrada.**



"""

entrada_altura = 256
entrada_largura = int(((proporcao * entrada_altura) * 8) // 8)

entrada_altura, entrada_largura

"""## **Etapa 8 - Converter a imagem do formato openCV para o formato blob Caffe**"""

entrada_blob = cv2.dnn.blobFromImage(imagem, 1.0 / 255, 
                                     (entrada_largura, entrada_altura), 
                                     (0, 0, 0), swapRB=False, crop=False)

"""## **Etapa 9 - Saída**"""

modelo.setInput(entrada_blob) #Fazendo a previsao e setando a variavel de saida
saida = modelo.forward()

saida.shape #ID imagem, numero de pontos, localização ponto vertical, localização ponto horizontal

"""## **Etapa 10 - Plotando as saídas na imagem**


"""

pontos = []
limite = 0.1
for i in range(numero_pontos): #Percorre o numero de pontos
    mapa_confianca = saida[0, i, :, :] #Define o mapa de confiança
    mapa_confianca = cv2.resize(mapa_confianca, (imagem_largura, imagem_altura)) #Faz o resize desse mapa de confiança de acordo a altura e largura da imagem

    _, confianca, _, ponto = cv2.minMaxLoc(mapa_confianca) #por essa função minMaxLoc, resgata o valor da confianca e o valor do ponto

    if confianca > limite: #Se a confiança é maior que o limite
        #Desenha um circulo na imagem da copia
        cv2.circle(imagem_copia, (int(ponto[0]), int(ponto[1])), 5, cor_pontoA, 
                   thickness=espessura, lineType=cv2.FILLED)  
        #Escreve um texto na imagem da copia
        cv2.putText(imagem_copia, ' ' + (str(int(ponto[0]))) + ',' + 
                    str(int(ponto[1])), (int(ponto[0]), int(ponto[1])),
                    fonte, 0.3, cor_txtponto, 0, lineType=cv2.LINE_AA) 

        #Desenha um circulo na imagem original
        cv2.circle(imagem, (int(ponto[0]), int(ponto[1])), tamanho_circulo,
                   cor_pontoA,
                   thickness=espessura, lineType=cv2.FILLED) 
        #Escreve um texto na imagem original
        cv2.putText(imagem, ' ' + "{}".format(i), (int(ponto[0]), 
                                                  int(ponto[1])), 
                    cv2.FONT_HERSHEY_SIMPLEX, 0.3,
                    cor_txtponto,
                    0, lineType=cv2.LINE_AA)
        #Adiciona os pontos para fazer o esqueleto de mapeação
        pontos.append((int(ponto[0]), int(ponto[1])))

    else: #Se não
        pontos.append((0, 0)) #Deixa o arrray vazio

len(pontos) #numero de pontos que o algoritmo detectou

print(pontos) #mostra os pontos e a localização de cada ponto

cv2.imshow("Mostrando os pontos",imagem_copia)

"""## **Etapa 11 - Desenhar o esqueleto: quando temos os pontos chave, apenas juntamos os pares**"""

for par in pares_poses: #Definido na etapa 4
    parteA = par[0]
    parteB = par[1]

    if pontos[parteA] != (0, 0) and pontos[parteB] != (0, 0): #Verifica se os pontos a e b são diferente de quando a imagem não passa do limite de confiança
        #Se sim faz o desenho na imagem e na imagem copia
        cv2.line(imagem_copia, pontos[parteA], pontos[parteB], cor_linha, 
                 tamanho_linha, lineType=cv2.LINE_AA)
        cv2.line(imagem, pontos[parteA], pontos[parteB], cor_linha, tamanho_linha, 
                 lineType=cv2.LINE_AA)

cv2.imshow("Definição das linhas",imagem_copia)

"""## Etapa  12 - Verificar posição dos dedos e da mão

Usar a função verificar_posicao_DEDOS para verificar se os dedos estão dobrados, estidados na vertical ou esticados na hoprizontal.

Parâmetros das funções:

> Passamos como parâmetro para a função, o vetor de pontos detectados, limitando as articulações de cada dedo da mão. 

> A função verificar_altura_MAO, verifica se a posição da mão está voltada para cima ou para baixo


*   Pontos do 1 ao 5, correspondem ao dedo polegar
** Para o dedo polegar, precisa de uma verificação adicional para saber se está esticado ou dobrado comparando a diferença dos pontos na vertical e na horizontal
*   Pontos do 5 ao 9, correspondem ao dedo indicador
*   Pontos do 9 ao 13, correspondem ao dedo médio
*   Pontos do 13 ao 17, correspondem ao dedo anelar
*   Pontos do 17 ao 21, correspondem ao dedo mínimo
"""

posicao.posicoes = [] #acessando a lista do extrator posições para ver como estão as posições dos deodos

# Dedo polegar
posicao.verificar_posicao_DEDOS(pontos[1:5], 'polegar', altura.verificar_altura_MAO(pontos))

# Dedo indicador
posicao.verificar_posicao_DEDOS(pontos[5:9], 'indicador', altura.verificar_altura_MAO(pontos))

# Dedo médio
posicao.verificar_posicao_DEDOS(pontos[9:13], 'medio', altura.verificar_altura_MAO(pontos))

# Dedo anelar
posicao.verificar_posicao_DEDOS(pontos[13:17], 'anelar', altura.verificar_altura_MAO(pontos))

# Dedo mínimo
posicao.verificar_posicao_DEDOS(pontos[17:21], 'minimo', altura.verificar_altura_MAO(pontos))

posicao.posicoes

"""## Etapa 13 - Verificar a proximidade entre os dedos

Após verificar se os dedos estão dobrados ou esticados, vericamos a proximidade entre os dedos com a função verificar_proximidade_DEDOS

Esta função faz a verificação da proximidade entre dedos, 
comparando se os dedos estão lado a lado e se estão na mesma posição (esticados ou dobrados).

Se forem iguais, então significa que estão próximos.

> Recebe como parâmetro todo o vetor de pontos

> Na função verificar_proximidade_DEDOS, para cada variável que corresponde as articulações dos dedos, não foram utilizados os nomes "científicos"

> O resultado será o vetor de características de todos os dedos da mão
"""

p = proximidade.verificar_proximidade_DEDOS(pontos)

p

"""## Etapa 14 - Comparando as características"""

for i, a in enumerate(alfabeto.letras):
  if proximidade.verificar_proximidade_DEDOS(pontos) == alfabeto.letras[i]:
    cv2.putText(imagem, ' ' + letras[i], (50,50), fonte, 1, cor_txtponto,
                tamanho_fonte, lineType=cv2.LINE_AA)
    print("Letra identificada", letras[i])

"""## **Etapa 15 - Exibindo as saídas**"""

plt.figure(figsize = [14,10])
plt.imshow(cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB))
plt.show()
cv2.waitKey(0)